\section{Analysis}\label{sec:analysis}
The analysis is divided into three different categories.
However, it should be said at this point that these categories will have overlaps.
Therefore, to avoid mentioning topics several times they will be mentioned only once.

\subsection{User}
The primary users for this application are persons with mental distress.
The question in this case is how is mental distress defined, or who is affected by it?
This question gets answered when looking into the core beliefs in the development of Woebot \cite{woebot-beliefs}.

\begin{quote}
    Everybody struggles sometimes. Cognitive distortions are something that everyone experiences in the context of strong emotion; it's part of being human.
\end{quote}

This quote shows clearly that not only persons with strong mental distress should consider using Woebot, but the application is for everyone.
The problem is that design for everyone holds the potential to exclude users by design\cite{feminist-technology}.
Designing for everyone is especially hard, because the human abilities and disabilities are a very wide range.
There are numerous counterexamples for users that do not fall into the extremely broad target group.
Everyone only includes persons being capable of the English language.
And even then it might be hard for persons with dyslexia to communicate with Woebot.\textcolor{red}{ Dyslexia cite}\\

\begin{figure}[ht]
    \begin{center}
        \includegraphics[width=1\columnwidth]{files/dyslexia.png}
        \caption{\label{fig:dyslexia} Cropped screenshot of a misunderstood call for help}
    \end{center}
\end{figure}

\autoref{fig:dyslexia} illustrates the problems that could happen when a typo occurs and Woebot cannot understand the user correctly.
Woebot reacts inappropriate to a user trying to talk about being stressed.
Instead of helping Woebot misunderstands the user and continues suggesting a game, followed up by joking around.
This behavior obviously neglects the feelings of the user.
It has also been observed in a study conducted in 2020\cite{investigating-students}.
Not only did the users feel misunderstood, but the conversations felt repetitive.
Even more problematic is the fact that the user cannot abort the current interaction and is forced to choose one of the predefined answers.\\

The figure also reveals the different problems with NLP, which will be further described in \autoref{sec:design}.
Typos could happen to many target groups.
People with cognitive or motoric disabilities could be affected by this.
A user group that may also not be considered are persons using a dialect of English and therefore be misunderstood.\\

A rather obvious counterexample is the general usage of the application.
It can only be accessed when the people wanting to use the application own a smartphone.
Although Woebot is capable of suggesting different lessons for relationships it is not capable for usage with more than one user.
The usage of the application is only limited to a single user.\\

% How does it suggest to approach mental health? - Selfmanagement? Through Interaction?
% Norms and values: Culture sees mental problems as weakness -> Woebot doesn't solve this norm, it rather fights the weakness

% GIFs + Emojis - Personal but might be annoying/ not for every target group

\subsection{Design}\label{sec:design}
Woebot is designed as a robot, as the suffix -bot suggests.
The chosen visual design for Woebot seems to be genderless.
This is an interesting design choice, because choosing a gender for a robot can influence human behavior towards the robot.
Researches found out that female voices for example are preferred over male or computer voices\cite{bias-robot}.
Other research has shown that female clients prefer a female therapist and male clients have no preference (58\%), but would rather prefer a female than a male (32\%)\cite{client-gender-preference}.
The reason for preference were among others the feeling of comfort with a female therapist.
Normally such findings would indicate that designing a female conversational agent would lead to a better product.\\

However, a female robot might not only reinforce gender stereotypes, but also reinforce abusive behavior towards the robot\cite{nomura-robot, visual-gender}.
Given the different factors of choosing a gender for a robot, picking a genderless robot seems to be the best solution.
A genderless design does not challenge current gender stereotypes, but it does not reinforce them either.
Woebot is designed with large eyes and a small chin.
This design has been examined and shown that it is perceived as naive, honest, kind and warm\cite{robot-design}.
The perception seems to be similar as the perceived traits of a female therapist, but has to be further examined.\\

Many of Woebot's design problems can be traced back to the first chatbot, ELIZA.
The creator of ELIZA discovered early, that his secretary anthropomorphized the chatbot ELIZA\cite{eliza-chatbot}.
That is not an isolated case, but humans in general tend to anthropomorphize machines.
Computers are social actors (CASA) is the paradigm that describes this phenomenon\cite{casa-first, people-computers}.
This phenomenon can also be transferred to Woebot.
Even if Woebot calls himself a robot, it cannot prevent humans from anthropomorphizing it.
A strong indication for this is a study that shows the therapeutic bond that Woebot is capable of establishing with the user\cite{therapeutic-bond}.
This seems to be a double-edged sword.
The therapeutic bond with the patient ensures that the patient feels more understood.
However, this understanding is only an illusion because Woebot cannot truly understand the user's thoughts.
It could happen that users interpret more knowledge processing into Woebot than it can actually do.\\

Processing user input using NLP is another problem that has accompanied ELIZA's invention.
As shown in \autoref{fig:dyslexia}, Woebot is not able to recognize typos.
In the event of misunderstandings, Woebot reacts with predefined sentences.
However, typos are not the only source of error that occur in a system using NLP.
Misunderstandings can occur for a number of reasons, typos being only one of them.

Language is multifaceted and this is exactly where the problem for a text based conversational agent lies.
Phrases can have multiple meanings.
An example for this are homonyms.
Words that have the same spelling but have different meanings.
Semantic ambiguity can also occur in whole sentences.
An example would be: "Call me a doctor".
This could either mean that the person saying this sentence would like to talk to a doctor or would like to be called a doctor.
This ambiguity could be reduced by giving more context.
"I would like you to call a doctor for me" or "Please refer to me as a doctor" would be examples for disambiguation.
Without enough context it is not possible for NLP to process the true meaning of a word or sentence.\\

These problems lie in the design of Woebot.
Due to the chat-like design users might be encouraged to text like they would in a chat with their friends.
Users tend to write without proper punctuation in chat-like services\cite{punctuation}.
The lack of punctuation in instant messaging services are another example for prone to error and lack of context.
The popular example "Let's eat grandpa" and "Let's eat, grandpa" illustrates the problem.
Additionally, an analysis of message length in WhatsApp shows that around 87\% of all messages contain one to ten words\cite{whatsapp-usage}.
The data cannot be transferred completely to Woebot because users may use the application differently than other chat services.
However, the short message length of Woebot and the use of emojis speak for similar results as in the just mentioned study.
According to a psychologist these misunderstandings could have a very negative impact on the user.

\begin{quote}
    If this happened in therapy, the therapist may lose the client's trust and risk damaging their rapport or therapeutic alliance because it may come across as the therapist ignoring the client's feelings.
    If the client feels unseen/unheard, s/he may not be as receptive to the skills/ lessons available to them in therapy\cite{investigating-students}.
\end{quote}

Ready-made answers ensure that the source of error is reduced, but this also ensures that users are forced to give certain answers.
This limitation has the problem that users cannot identify themselves with certain answers\cite{emoticons}.\\

In addition to language-related problems, there are also social and ethical concerns.
Depending on the dataset, linguistic algorithms may contain biased data, which is essentially represented as stereotypical data.
There are many examples of gender bias in NLP as research has shown\cite{gender-bias-nlp}.
Likewise, the origins of bias are also varied\cite{sources-bias-nlp}.\\

% NLP - users may not be aware of how much information a conversation shares
% Does it collect data, what does the app do with the data?

% Mood-Tracker:
% Not possible to click on emojis
% What looks like a prediction is actually none

% scrolling up - no jump down button
% Wrong calculations

\subsection{Context}
% Biometric sensor - privacy - phonesharing context
% Internet connection - Different contexts?
% Preload videos?

%%%%% General TODO %%%%%
% CEO & Founder explanation - Design with actors from the relevant field
% Woebot’s terms of service call it a “pure self-help”
